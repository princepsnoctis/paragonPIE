{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-29T05:31:23.088507500Z",
     "start_time": "2025-11-29T05:31:17.715187Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%run 2_converter.ipynb\n",
    "%run 3_dataset.ipynb\n",
    "%run 4_batching.ipynb\n",
    "%run 7_model.ipynb"
   ],
   "id": "ec362147ba422cbc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ', '!', '\"', '#', '%', '&', \"'\", '(', '*', '+', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', '=', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '\\\\', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '|', 'Ó', 'ó', 'Ą', 'ą', 'Ć', 'ć', 'Ę', 'ę', 'Ł', 'ł', 'ń', 'Ś', 'ś', 'ź', 'Ż', 'ż']\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'unit'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyError\u001B[39m                                  Traceback (most recent call last)",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\Paragon Roadmap\\ParagonPIE\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001B[39m, in \u001B[36mIndex.get_loc\u001B[39m\u001B[34m(self, key)\u001B[39m\n\u001B[32m   3811\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m3812\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_engine\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcasted_key\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   3813\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "\u001B[36mFile \u001B[39m\u001B[32mpandas/_libs/index.pyx:167\u001B[39m, in \u001B[36mpandas._libs.index.IndexEngine.get_loc\u001B[39m\u001B[34m()\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mpandas/_libs/index.pyx:196\u001B[39m, in \u001B[36mpandas._libs.index.IndexEngine.get_loc\u001B[39m\u001B[34m()\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mpandas/_libs/hashtable_class_helper.pxi:7088\u001B[39m, in \u001B[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[39m\u001B[34m()\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mpandas/_libs/hashtable_class_helper.pxi:7096\u001B[39m, in \u001B[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[39m\u001B[34m()\u001B[39m\n",
      "\u001B[31mKeyError\u001B[39m: 'unit'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[31mKeyError\u001B[39m                                  Traceback (most recent call last)",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Temp\\ipykernel_2128\\543290336.py:9\u001B[39m\n\u001B[32m      6\u001B[39m \u001B[38;5;28mprint\u001B[39m(name_symbols)\n\u001B[32m      8\u001B[39m \u001B[38;5;66;03m# Unit\u001B[39;00m\n\u001B[32m----> \u001B[39m\u001B[32m9\u001B[39m unit_symbols = \u001B[43mextract_all_unique_column_values\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43m../data/train.csv\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43munit\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m     10\u001B[39m unit_converter = Converter(symbols=unit_symbols, special_symbols=[\u001B[33m\"\u001B[39m\u001B[33m<NONE>\u001B[39m\u001B[33m\"\u001B[39m])\n\u001B[32m     11\u001B[39m \u001B[38;5;28mprint\u001B[39m(unit_symbols)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Temp\\ipykernel_2128\\4216143627.py:12\u001B[39m, in \u001B[36mextract_all_unique_column_values\u001B[39m\u001B[34m(path_to_csv, column)\u001B[39m\n\u001B[32m      9\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mextract_all_unique_column_values\u001B[39m(path_to_csv, column):\n\u001B[32m     10\u001B[39m     df = pd.read_csv(path_to_csv, sep=\u001B[33m\"\u001B[39m\u001B[33m;\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m---> \u001B[39m\u001B[32m12\u001B[39m     filtered = \u001B[43mdf\u001B[49m\u001B[43m[\u001B[49m\u001B[43mcolumn\u001B[49m\u001B[43m]\u001B[49m.dropna()\n\u001B[32m     13\u001B[39m     filtered = filtered[filtered != \u001B[33m\"\u001B[39m\u001B[33m\"\u001B[39m]\n\u001B[32m     15\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m filtered.unique().tolist()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\Paragon Roadmap\\ParagonPIE\\.venv\\Lib\\site-packages\\pandas\\core\\frame.py:4113\u001B[39m, in \u001B[36mDataFrame.__getitem__\u001B[39m\u001B[34m(self, key)\u001B[39m\n\u001B[32m   4111\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.columns.nlevels > \u001B[32m1\u001B[39m:\n\u001B[32m   4112\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._getitem_multilevel(key)\n\u001B[32m-> \u001B[39m\u001B[32m4113\u001B[39m indexer = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mcolumns\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   4114\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m is_integer(indexer):\n\u001B[32m   4115\u001B[39m     indexer = [indexer]\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\Paragon Roadmap\\ParagonPIE\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3819\u001B[39m, in \u001B[36mIndex.get_loc\u001B[39m\u001B[34m(self, key)\u001B[39m\n\u001B[32m   3814\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(casted_key, \u001B[38;5;28mslice\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m (\n\u001B[32m   3815\u001B[39m         \u001B[38;5;28misinstance\u001B[39m(casted_key, abc.Iterable)\n\u001B[32m   3816\u001B[39m         \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28many\u001B[39m(\u001B[38;5;28misinstance\u001B[39m(x, \u001B[38;5;28mslice\u001B[39m) \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m casted_key)\n\u001B[32m   3817\u001B[39m     ):\n\u001B[32m   3818\u001B[39m         \u001B[38;5;28;01mraise\u001B[39;00m InvalidIndexError(key)\n\u001B[32m-> \u001B[39m\u001B[32m3819\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01merr\u001B[39;00m\n\u001B[32m   3820\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[32m   3821\u001B[39m     \u001B[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001B[39;00m\n\u001B[32m   3822\u001B[39m     \u001B[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001B[39;00m\n\u001B[32m   3823\u001B[39m     \u001B[38;5;66;03m#  the TypeError.\u001B[39;00m\n\u001B[32m   3824\u001B[39m     \u001B[38;5;28mself\u001B[39m._check_indexing_error(key)\n",
      "\u001B[31mKeyError\u001B[39m: 'unit'"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'unit'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyError\u001B[39m                                  Traceback (most recent call last)",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\Paragon Roadmap\\ParagonPIE\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001B[39m, in \u001B[36mIndex.get_loc\u001B[39m\u001B[34m(self, key)\u001B[39m\n\u001B[32m   3811\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m3812\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_engine\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcasted_key\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   3813\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "\u001B[36mFile \u001B[39m\u001B[32mpandas/_libs/index.pyx:167\u001B[39m, in \u001B[36mpandas._libs.index.IndexEngine.get_loc\u001B[39m\u001B[34m()\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mpandas/_libs/index.pyx:196\u001B[39m, in \u001B[36mpandas._libs.index.IndexEngine.get_loc\u001B[39m\u001B[34m()\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mpandas/_libs/hashtable_class_helper.pxi:7088\u001B[39m, in \u001B[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[39m\u001B[34m()\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mpandas/_libs/hashtable_class_helper.pxi:7096\u001B[39m, in \u001B[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[39m\u001B[34m()\u001B[39m\n",
      "\u001B[31mKeyError\u001B[39m: 'unit'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[31mKeyError\u001B[39m                                  Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[1]\u001B[39m\u001B[32m, line 2\u001B[39m\n\u001B[32m      1\u001B[39m get_ipython().run_line_magic(\u001B[33m'\u001B[39m\u001B[33mrun\u001B[39m\u001B[33m'\u001B[39m, \u001B[33m'\u001B[39m\u001B[33m2_converter.ipynb\u001B[39m\u001B[33m'\u001B[39m)\n\u001B[32m----> \u001B[39m\u001B[32m2\u001B[39m \u001B[43mget_ipython\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43mrun_line_magic\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mrun\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43m3_dataset.ipynb\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m      3\u001B[39m get_ipython().run_line_magic(\u001B[33m'\u001B[39m\u001B[33mrun\u001B[39m\u001B[33m'\u001B[39m, \u001B[33m'\u001B[39m\u001B[33m4_batching.ipynb\u001B[39m\u001B[33m'\u001B[39m)\n\u001B[32m      4\u001B[39m get_ipython().run_line_magic(\u001B[33m'\u001B[39m\u001B[33mrun\u001B[39m\u001B[33m'\u001B[39m, \u001B[33m'\u001B[39m\u001B[33m7_model.ipynb\u001B[39m\u001B[33m'\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\Paragon Roadmap\\ParagonPIE\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:2504\u001B[39m, in \u001B[36mInteractiveShell.run_line_magic\u001B[39m\u001B[34m(self, magic_name, line, _stack_depth)\u001B[39m\n\u001B[32m   2502\u001B[39m     kwargs[\u001B[33m'\u001B[39m\u001B[33mlocal_ns\u001B[39m\u001B[33m'\u001B[39m] = \u001B[38;5;28mself\u001B[39m.get_local_scope(stack_depth)\n\u001B[32m   2503\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m.builtin_trap:\n\u001B[32m-> \u001B[39m\u001B[32m2504\u001B[39m     result = \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   2506\u001B[39m \u001B[38;5;66;03m# The code below prevents the output from being displayed\u001B[39;00m\n\u001B[32m   2507\u001B[39m \u001B[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001B[39;00m\n\u001B[32m   2508\u001B[39m \u001B[38;5;66;03m# when the last Python token in the expression is a ';'.\u001B[39;00m\n\u001B[32m   2509\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(fn, magic.MAGIC_OUTPUT_CAN_BE_SILENCED, \u001B[38;5;28;01mFalse\u001B[39;00m):\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\Paragon Roadmap\\ParagonPIE\\.venv\\Lib\\site-packages\\IPython\\core\\magics\\execution.py:749\u001B[39m, in \u001B[36mExecutionMagics.run\u001B[39m\u001B[34m(self, parameter_s, runner, file_finder)\u001B[39m\n\u001B[32m    747\u001B[39m     \u001B[38;5;28;01mwith\u001B[39;00m preserve_keys(\u001B[38;5;28mself\u001B[39m.shell.user_ns, \u001B[33m'\u001B[39m\u001B[33m__file__\u001B[39m\u001B[33m'\u001B[39m):\n\u001B[32m    748\u001B[39m         \u001B[38;5;28mself\u001B[39m.shell.user_ns[\u001B[33m'\u001B[39m\u001B[33m__file__\u001B[39m\u001B[33m'\u001B[39m] = filename\n\u001B[32m--> \u001B[39m\u001B[32m749\u001B[39m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mshell\u001B[49m\u001B[43m.\u001B[49m\u001B[43msafe_execfile_ipy\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilename\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mraise_exceptions\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[32m    750\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m\n\u001B[32m    752\u001B[39m \u001B[38;5;66;03m# Control the response to exit() calls made by the script being run\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\Paragon Roadmap\\ParagonPIE\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:2995\u001B[39m, in \u001B[36mInteractiveShell.safe_execfile_ipy\u001B[39m\u001B[34m(self, fname, shell_futures, raise_exceptions)\u001B[39m\n\u001B[32m   2993\u001B[39m result = \u001B[38;5;28mself\u001B[39m.run_cell(cell, silent=\u001B[38;5;28;01mTrue\u001B[39;00m, shell_futures=shell_futures)\n\u001B[32m   2994\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m raise_exceptions:\n\u001B[32m-> \u001B[39m\u001B[32m2995\u001B[39m     \u001B[43mresult\u001B[49m\u001B[43m.\u001B[49m\u001B[43mraise_error\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   2996\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m result.success:\n\u001B[32m   2997\u001B[39m     \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\Paragon Roadmap\\ParagonPIE\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:326\u001B[39m, in \u001B[36mExecutionResult.raise_error\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    324\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mself\u001B[39m.error_before_exec\n\u001B[32m    325\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.error_in_exec \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m326\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mself\u001B[39m.error_in_exec\n",
      "    \u001B[31m[... skipping hidden 1 frame]\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Temp\\ipykernel_2128\\543290336.py:9\u001B[39m\n\u001B[32m      6\u001B[39m \u001B[38;5;28mprint\u001B[39m(name_symbols)\n\u001B[32m      8\u001B[39m \u001B[38;5;66;03m# Unit\u001B[39;00m\n\u001B[32m----> \u001B[39m\u001B[32m9\u001B[39m unit_symbols = \u001B[43mextract_all_unique_column_values\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43m../data/train.csv\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43munit\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m     10\u001B[39m unit_converter = Converter(symbols=unit_symbols, special_symbols=[\u001B[33m\"\u001B[39m\u001B[33m<NONE>\u001B[39m\u001B[33m\"\u001B[39m])\n\u001B[32m     11\u001B[39m \u001B[38;5;28mprint\u001B[39m(unit_symbols)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Temp\\ipykernel_2128\\4216143627.py:12\u001B[39m, in \u001B[36mextract_all_unique_column_values\u001B[39m\u001B[34m(path_to_csv, column)\u001B[39m\n\u001B[32m      9\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mextract_all_unique_column_values\u001B[39m(path_to_csv, column):\n\u001B[32m     10\u001B[39m     df = pd.read_csv(path_to_csv, sep=\u001B[33m\"\u001B[39m\u001B[33m;\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m---> \u001B[39m\u001B[32m12\u001B[39m     filtered = \u001B[43mdf\u001B[49m\u001B[43m[\u001B[49m\u001B[43mcolumn\u001B[49m\u001B[43m]\u001B[49m.dropna()\n\u001B[32m     13\u001B[39m     filtered = filtered[filtered != \u001B[33m\"\u001B[39m\u001B[33m\"\u001B[39m]\n\u001B[32m     15\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m filtered.unique().tolist()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\Paragon Roadmap\\ParagonPIE\\.venv\\Lib\\site-packages\\pandas\\core\\frame.py:4113\u001B[39m, in \u001B[36mDataFrame.__getitem__\u001B[39m\u001B[34m(self, key)\u001B[39m\n\u001B[32m   4111\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.columns.nlevels > \u001B[32m1\u001B[39m:\n\u001B[32m   4112\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._getitem_multilevel(key)\n\u001B[32m-> \u001B[39m\u001B[32m4113\u001B[39m indexer = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mcolumns\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   4114\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m is_integer(indexer):\n\u001B[32m   4115\u001B[39m     indexer = [indexer]\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\Paragon Roadmap\\ParagonPIE\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3819\u001B[39m, in \u001B[36mIndex.get_loc\u001B[39m\u001B[34m(self, key)\u001B[39m\n\u001B[32m   3814\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(casted_key, \u001B[38;5;28mslice\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m (\n\u001B[32m   3815\u001B[39m         \u001B[38;5;28misinstance\u001B[39m(casted_key, abc.Iterable)\n\u001B[32m   3816\u001B[39m         \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28many\u001B[39m(\u001B[38;5;28misinstance\u001B[39m(x, \u001B[38;5;28mslice\u001B[39m) \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m casted_key)\n\u001B[32m   3817\u001B[39m     ):\n\u001B[32m   3818\u001B[39m         \u001B[38;5;28;01mraise\u001B[39;00m InvalidIndexError(key)\n\u001B[32m-> \u001B[39m\u001B[32m3819\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01merr\u001B[39;00m\n\u001B[32m   3820\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[32m   3821\u001B[39m     \u001B[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001B[39;00m\n\u001B[32m   3822\u001B[39m     \u001B[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001B[39;00m\n\u001B[32m   3823\u001B[39m     \u001B[38;5;66;03m#  the TypeError.\u001B[39;00m\n\u001B[32m   3824\u001B[39m     \u001B[38;5;28mself\u001B[39m._check_indexing_error(key)\n",
      "\u001B[31mKeyError\u001B[39m: 'unit'"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "import torch",
   "id": "e11b7ac89976888c",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "def load_model(checkpoint_path, dataset, emb_dim=256, num_heads=8, ff_dim=1024, dropout=0.25, num_layers=4, device=\"cuda\"):\n",
    "    model = Model(\n",
    "        sym_len=len(dataset.name_converter),\n",
    "        max_sam_len=max(len(x[0]) for x in dataset),\n",
    "        max_nam_len=max(len(x[1][\"name\"]) for x in dataset),\n",
    "        unit_cat_len=len(dataset.unit_converter),\n",
    "        tax_cat_len=len(dataset.tax_converter),\n",
    "        emb_dim=emb_dim,\n",
    "        num_heads=num_heads,\n",
    "        ff_dim=ff_dim,\n",
    "        dropout=dropout,\n",
    "        num_layers=num_layers,\n",
    "    )\n",
    "\n",
    "    model.load_state_dict(torch.load(checkpoint_path, map_location=device))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    return model"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def decode_name(token_ids, name_converter):\n",
    "    # token_ids: a 1D tensor of ids\n",
    "    # convert to string using your converter decode (you may strip BOS/EOS/PAD)\n",
    "    tokens = token_ids.tolist()\n",
    "    # remove leading BOS and everything from EOS on\n",
    "    if name_converter[\"<BOS>\"] in tokens:\n",
    "        tokens = tokens[tokens.index(name_converter[\"<BOS>\"])+1:]\n",
    "    if name_converter[\"<EOS>\"] in tokens:\n",
    "        tokens = tokens[:tokens.index(name_converter[\"<EOS>\"])]\n",
    "    # use converter to decode sequence of ints into string:\n",
    "    return name_converter.decode_seq(tokens)   # adjust if your converter has different API\n"
   ],
   "id": "198274be0c254ae8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def decode_category(logits, converter):\n",
    "    idx = logits.argmax(dim=-1).item()\n",
    "    return converter.decode(idx)"
   ],
   "id": "89fe516dd5f7f8bc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def decode_regression(x):\n",
    "    x = x.item()\n",
    "    x = max(x, 0)\n",
    "    return float(torch.expm1(torch.tensor(x)).item())"
   ],
   "id": "abaf3f3ae5dfa38c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def predict_one(model, text, name_converter, unit_converter, tax_converter,\n",
    "                device=\"cpu\", max_len=50):\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    # Encode sample\n",
    "    enc_tokens = torch.tensor(\n",
    "        name_converter.encode_seq(text),\n",
    "        dtype=torch.long,\n",
    "        device=device\n",
    "    ).unsqueeze(0)               # (1, L)\n",
    "\n",
    "    sample_mask = torch.zeros(enc_tokens.shape, dtype=torch.bool, device=device)\n",
    "\n",
    "    # Encoder forward\n",
    "    enc_emb = model.encoder_embedding(enc_tokens)\n",
    "    enc_out = model.encoder(enc_emb, sample_mask)\n",
    "\n",
    "    # -------------------------------------------------------\n",
    "    # NO NAME GENERATION — we create a dummy decoder input\n",
    "    # -------------------------------------------------------\n",
    "    # Use a single BOS token as decoder input\n",
    "    sos_id = int(name_converter[\"<BOS>\"])\n",
    "    dec_inp = torch.tensor([[sos_id]], device=device)\n",
    "\n",
    "    dec_emb = model.decoder_embedding(dec_inp)\n",
    "\n",
    "    # masks\n",
    "    name_mask = dec_inp.eq(int(name_converter[\"<PAD>\"]))   # trivial but needed\n",
    "    sample_mask = torch.zeros(enc_out.size()[:2], dtype=torch.bool, device=device)\n",
    "\n",
    "    # Decoder forward\n",
    "    dec_out = model.decoder(\n",
    "        decoder_input=dec_emb,\n",
    "        encoder_output=enc_out,\n",
    "        name_mask=name_mask,\n",
    "        sample_mask=sample_mask\n",
    "    )\n",
    "\n",
    "    # Multihead (unit/tax/regression)\n",
    "    out = model.multihead(enc_out, dec_out)\n",
    "\n",
    "    # Decode heads\n",
    "    unit_pred_id = out[\"unit_logits\"].argmax(dim=-1).item()\n",
    "    tax_pred_id  = out[\"tax_logits\"].argmax(dim=-1).item()\n",
    "\n",
    "    unit_text = unit_converter.decode(unit_pred_id)\n",
    "    tax_text  = tax_converter.decode(tax_pred_id)\n",
    "\n",
    "    amount   = float(out[\"amount_pred\"].item())\n",
    "    quantity = float(out[\"quantity_pred\"].item())\n",
    "    price    = float(out[\"price_pred\"].item())\n",
    "    total    = float(out[\"total_pred\"].item())\n",
    "\n",
    "    return {\n",
    "        \"unit\": unit_text,\n",
    "        \"tax\": tax_text,\n",
    "        \"quantity\": quantity,\n",
    "        \"amount\": amount,\n",
    "        \"price\": price,\n",
    "        \"total_price\": total,\n",
    "    }"
   ],
   "id": "18b0b799a9a0b129",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def predict_batch(model, texts, name_converter, unit_converter, tax_converter, device=\"cuda\"):\n",
    "    return [\n",
    "        predict_one(model, t, name_converter, unit_converter, tax_converter, device=device)\n",
    "        for t in texts\n",
    "    ]\n"
   ],
   "id": "d94e665b4d59af28",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "name_symbols = extract_all_symbols(\"../data/data.csv\")\n",
    "name_converter = Converter(\n",
    "    symbols=name_symbols,\n",
    "    special_symbols=[\"<PAD>\", \"<BOS>\", \"<EOS>\", \"<NONE>\"]\n",
    ")\n",
    "\n",
    "unit_symbols = extract_all_unique_column_values(\"../data/data.csv\", \"unit\")\n",
    "unit_converter = Converter(\n",
    "    symbols=unit_symbols,\n",
    "    special_symbols=[\"<NONE>\"]\n",
    ")\n",
    "\n",
    "tax_symbols = extract_all_unique_column_values(\"../data/data.csv\", \"tax_category\")\n",
    "tax_converter = Converter(\n",
    "    symbols=tax_symbols,\n",
    "    special_symbols=[\"<NONE>\"]\n",
    ")\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 2. Dataset + Collator\n",
    "# -------------------------------------------------------\n",
    "dataset = Dataset(\n",
    "    \"../data/data.csv\",\n",
    "    name_converter=name_converter,\n",
    "    unit_converter=unit_converter,\n",
    "    tax_converter=tax_converter\n",
    ")\n",
    "\n",
    "model = load_model(\"checkpoint.pt\", dataset)\n",
    "\n",
    "collator = Collator(converter=name_converter)\n",
    "\n",
    "result = predict_one(\n",
    "    model,\n",
    "    \"KLCBatontruskawkbana t 1SZT x8,56 8,56C\",\n",
    "    name_converter,\n",
    "    unit_converter,\n",
    "    tax_converter,\n",
    "    device=\"cuda\"\n",
    ")\n",
    "\n",
    "print(result)"
   ],
   "id": "2ab4c68dab43f095",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
