{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-26T21:29:12.168067300Z",
     "start_time": "2025-11-26T21:29:12.150125900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import pandas as pd"
   ],
   "id": "21c73e23839eda33",
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-26T21:29:12.176484900Z",
     "start_time": "2025-11-26T21:29:12.169067500Z"
    }
   },
   "source": [
    "class Collator:\n",
    "    def __init__(self, converter):\n",
    "        self.converter = converter\n",
    "\n",
    "    def __call__(self, batch):\n",
    "        max_sample_len = max([len(sample) for sample, _ in batch])\n",
    "        max_name_len = max([len(label[\"name\"]) for _, label in batch])\n",
    "\n",
    "        samples, labels = map(list, zip(*batch))\n",
    "        names = [label[\"name\"] for label in labels]\n",
    "\n",
    "        padded_samples = torch.nn.utils.rnn.pad_sequence(samples, batch_first=True, padding_value=self.converter[\"<PAD>\"])\n",
    "        padded_names = torch.nn.utils.rnn.pad_sequence(names, batch_first=True, padding_value=self.converter[\"<PAD>\"])\n",
    "\n",
    "        samples_attention_mask = (padded_samples == self.converter[\"<PAD>\"])\n",
    "        names_attention_mask = (padded_names == self.converter[\"<PAD>\"])\n",
    "\n",
    "        padded_labels = [{\n",
    "            **label,\n",
    "            \"name\": padded_name,\n",
    "        } for label, padded_name in zip(labels, padded_names)]\n",
    "\n",
    "        return padded_samples, padded_labels, samples_attention_mask, names_attention_mask"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-26T21:29:12.192286100Z",
     "start_time": "2025-11-26T21:29:12.177484600Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Helpers\n",
    "def extract_all_symbols(path_to_csv):\n",
    "    df = pd.read_csv(path_to_csv, dtype=str)\n",
    "\n",
    "    df_as_text = df.astype(str).agg(\"\".join, axis=1).str.cat()\n",
    "\n",
    "    return sorted(set(df_as_text))\n",
    "\n",
    "def extract_all_unique_column_values(path_to_csv, column):\n",
    "    df = pd.read_csv(path_to_csv)\n",
    "\n",
    "    filtered = df[column].dropna()\n",
    "    filtered = filtered[filtered != \"\"]\n",
    "\n",
    "    return filtered.unique().tolist()"
   ],
   "id": "e43b75d3306a6ce1",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-26T21:29:12.372336400Z",
     "start_time": "2025-11-26T21:29:12.192286100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%run 2_converter.ipynb\n",
    "%run 3_dataset.ipynb\n",
    "\n",
    "name_symbols = extract_all_symbols(\"../data/train.csv\")\n",
    "name_converter = Converter(symbols=name_symbols, special_symbols=[\"<PAD>\", \"<BOS>\", \"<EOS>\", \"<NONE>\"])\n",
    "\n",
    "unit_symbols = extract_all_unique_column_values(\"../data/train.csv\", \"unit\")\n",
    "unit_converter = Converter(symbols=unit_symbols, special_symbols=[\"<NONE>\"])\n",
    "\n",
    "tax_symbols = extract_all_unique_column_values(\"../data/train.csv\", \"tax_category\")\n",
    "tax_converter = Converter(symbols=tax_symbols, special_symbols=[\"<NONE>\"])\n",
    "\n",
    "dataset = Dataset(\"../data/data.csv\", name_converter=name_converter, unit_converter=unit_converter, tax_converter=tax_converter)\n",
    "\n",
    "collator = Collator(converter=name_converter)\n",
    "\n",
    "print(\"#######################################################\")\n",
    "collator([dataset[0], dataset[1]])"
   ],
   "id": "ec812df21ae2363e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ', '!', '\"', '#', '%', '&', \"'\", '(', '*', '+', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', '=', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '\\\\', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '|', 'Ó', 'ó', 'Ą', 'ą', 'Ć', 'ć', 'Ę', 'ę', 'Ł', 'ł', 'ń', 'Ś', 'ś', 'ź', 'Ż', 'ż']\n",
      "['KG', 'G', 'SZT', 'L', 'ML']\n",
      "['C', 'A', 'B', 'G', '0', 't', 'r', 'c', '4', 'a', '8', 'l', 'k']\n",
      "#######################################################\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[43, 31, 41, 31,  5, 32, 31, 49, 39, 31,  5, 20, 41, 37,  5, 33,  5, 28,\n",
       "           5, 82, 22, 15, 24, 28,  5, 22, 21, 15, 22, 20, 33,  1,  1,  1],\n",
       "         [56, 35, 42, 41, 39,  5, 41, 53,  5, 37, 53, 39, 31, 56, 34, 41,  5, 28,\n",
       "           5, 31,  5, 20,  5, 82, 22, 15, 28, 28,  5, 22, 15, 28, 28, 31]]),\n",
       " [{'name': tensor([43, 31, 41, 31,  5, 32, 31, 49, 39, 31,  5, 20, 41, 37,  1,  1]),\n",
       "   'unit': tensor(2),\n",
       "   'tax_category': tensor(2),\n",
       "   'quantity': tensor(9.),\n",
       "   'amount': tensor(1.),\n",
       "   'price': tensor(3.5900),\n",
       "   'total_price': tensor(32.3100),\n",
       "   'quantity_present': tensor(1, dtype=torch.int8),\n",
       "   'amount_present': tensor(1, dtype=torch.int8),\n",
       "   'price_present': tensor(1, dtype=torch.int8),\n",
       "   'total_price_present': tensor(1, dtype=torch.int8)},\n",
       "  {'name': tensor([56, 35, 42, 41, 39,  5, 41, 53,  5, 37, 53, 39, 31, 56, 34, 41]),\n",
       "   'unit': tensor(1),\n",
       "   'tax_category': tensor(3),\n",
       "   'quantity': tensor(1.),\n",
       "   'amount': tensor(-1.),\n",
       "   'price': tensor(3.9900),\n",
       "   'total_price': tensor(3.9900),\n",
       "   'quantity_present': tensor(1, dtype=torch.int8),\n",
       "   'amount_present': tensor(0, dtype=torch.int8),\n",
       "   'price_present': tensor(1, dtype=torch.int8),\n",
       "   'total_price_present': tensor(1, dtype=torch.int8)}],\n",
       " tensor([[False, False, False, False, False, False, False, False, False, False,\n",
       "          False, False, False, False, False, False, False, False, False, False,\n",
       "          False, False, False, False, False, False, False, False, False, False,\n",
       "          False,  True,  True,  True],\n",
       "         [False, False, False, False, False, False, False, False, False, False,\n",
       "          False, False, False, False, False, False, False, False, False, False,\n",
       "          False, False, False, False, False, False, False, False, False, False,\n",
       "          False, False, False, False]]),\n",
       " tensor([[False, False, False, False, False, False, False, False, False, False,\n",
       "          False, False, False, False,  True,  True],\n",
       "         [False, False, False, False, False, False, False, False, False, False,\n",
       "          False, False, False, False, False, False]]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
